{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP MLP ARCHITECTURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.sparse import csr_matrix \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dask.dataframe as dd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# if you keras is not using tensorflow as backend set \"KERAS_BACKEND=tensorflow\" use this command\n",
    "from keras.utils import np_utils \n",
    "from keras.datasets import mnist \n",
    "import seaborn as sns\n",
    "from keras.initializers import RandomNormal\n",
    "import tensorflow as tf\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('E:/BOOKS_NEW/Cases datasets/1st/reducing-commercial-aviation-fatalities/train_after_smoothening_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df_train = df_train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_train, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3893936, 31) (3893936,)\n",
      "(973485, 31) (973485,)\n",
      "-----------------------------------------------\n",
      "Features of x_train :  ['Unnamed0' 'Unnamed01' 'Unnamed011' 'Unnamed0111' 'crew' 'experiment'\n",
      " 'time' 'seat' 'smoothened_ecg_data' 'smoothened_r_data'\n",
      " 'smoothened_gsr_data' 'smoothened_eeg_fp1' 'smoothened_eeg_f7'\n",
      " 'smoothened_eeg_f8' 'smoothened_eeg_t4' 'smoothened_eeg_t6'\n",
      " 'smoothened_eeg_t5' 'smoothened_eeg_t3' 'smoothened_eeg_fp2'\n",
      " 'smoothened_eeg_o1' 'smoothened_eeg_p3' 'smoothened_eeg_pz'\n",
      " 'smoothened_eeg_f3' 'smoothened_eeg_fz' 'smoothened_eeg_f4'\n",
      " 'smoothened_eeg_c4' 'smoothened_eeg_p4' 'smoothened_eeg_poz'\n",
      " 'smoothened_eeg_c3' 'smoothened_eeg_cz' 'smoothened_eeg_o2']\n",
      "Features of x_test:  ['Unnamed0' 'Unnamed01' 'Unnamed011' 'Unnamed0111' 'crew' 'experiment'\n",
      " 'time' 'seat' 'smoothened_ecg_data' 'smoothened_r_data'\n",
      " 'smoothened_gsr_data' 'smoothened_eeg_fp1' 'smoothened_eeg_f7'\n",
      " 'smoothened_eeg_f8' 'smoothened_eeg_t4' 'smoothened_eeg_t6'\n",
      " 'smoothened_eeg_t5' 'smoothened_eeg_t3' 'smoothened_eeg_fp2'\n",
      " 'smoothened_eeg_o1' 'smoothened_eeg_p3' 'smoothened_eeg_pz'\n",
      " 'smoothened_eeg_f3' 'smoothened_eeg_fz' 'smoothened_eeg_f4'\n",
      " 'smoothened_eeg_c4' 'smoothened_eeg_p4' 'smoothened_eeg_poz'\n",
      " 'smoothened_eeg_c3' 'smoothened_eeg_cz' 'smoothened_eeg_o2']\n",
      "-----------------------------------------------\n",
      "Values of x_train :  [[3.28831000e+05 3.28831000e+05 3.28831000e+05 ... 5.45063504e-01\n",
      "  5.20916967e-01 4.83715469e-01]\n",
      " [2.98134400e+06 2.98134400e+06 2.98134400e+06 ... 5.27448961e-01\n",
      "  4.88764764e-01 4.75979250e-01]\n",
      " [6.50858000e+05 6.50858000e+05 6.50858000e+05 ... 5.30030911e-01\n",
      "  4.95758291e-01 4.80514391e-01]\n",
      " ...\n",
      " [2.23448900e+06 2.23448900e+06 2.23448900e+06 ... 5.31109515e-01\n",
      "  4.97930113e-01 4.78255085e-01]\n",
      " [4.30457200e+06 4.30457200e+06 4.30457200e+06 ... 5.38506263e-01\n",
      "  4.95897032e-01 4.79641639e-01]\n",
      " [1.69274300e+06 1.69274300e+06 1.69274300e+06 ... 5.37767844e-01\n",
      "  5.06461630e-01 4.78732654e-01]]\n",
      "Values of x_test :  [[4.42013100e+06 4.42013100e+06 4.42013100e+06 ... 5.31221305e-01\n",
      "  4.95131573e-01 4.77288355e-01]\n",
      " [3.75011900e+06 3.75011900e+06 3.75011900e+06 ... 5.33895534e-01\n",
      "  4.94823484e-01 4.81930411e-01]\n",
      " [2.79566700e+06 2.79566700e+06 2.79566700e+06 ... 5.40263470e-01\n",
      "  5.04561596e-01 4.78348693e-01]\n",
      " ...\n",
      " [3.07289600e+06 3.07289600e+06 3.07289600e+06 ... 5.60872478e-01\n",
      "  5.02852210e-01 4.61346614e-01]\n",
      " [1.79954100e+06 1.79954100e+06 1.79954100e+06 ... 5.28769887e-01\n",
      "  5.01095350e-01 4.86611588e-01]\n",
      " [3.28538800e+06 3.28538800e+06 3.28538800e+06 ... 5.35239563e-01\n",
      "  4.98890899e-01 4.76944852e-01]]\n",
      "-----------------------------------------------\n",
      "Values of y_train:  [0 0 0 ... 2 0 2]\n",
      "Values of y_test:  [2 0 2 ... 0 3 2]\n"
     ]
    }
   ],
   "source": [
    "x_train = train.loc[:, df_train.columns != 'event']\n",
    "y_train = train['event']\n",
    "\n",
    "x_test = test.loc[:, df_train.columns != 'event']\n",
    "y_test = test['event']\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)\n",
    "print('-----------------------------------------------')\n",
    "print('Features of x_train : ', x_train.columns.values)\n",
    "print('Features of x_test: ', x_test.columns.values)\n",
    "print('-----------------------------------------------')\n",
    "print('Values of x_train : ', x_train.values)\n",
    "print('Values of x_test : ', x_test.values)\n",
    "print('-----------------------------------------------')\n",
    "print('Values of y_train: ', y_train.values)\n",
    "print('Values of y_test: ', y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06755736 0.06755736 0.06755736 ... 0.54502693 0.49846334 0.48371547]\n",
      " [0.61251004 0.61251004 0.61251004 ... 0.52741097 0.46480423 0.47597925]\n",
      " [0.13371707 0.13371707 0.13371707 ... 0.52999312 0.47212553 0.48051439]\n",
      " ...\n",
      " [0.4590704  0.4590704  0.4590704  ... 0.53107181 0.47439914 0.47825508]\n",
      " [0.88436418 0.88436418 0.88436418 ... 0.53846916 0.47227077 0.47964164]\n",
      " [0.34776994 0.34776994 0.34776994 ... 0.53773068 0.48333051 0.47873265]]\n",
      "------------------------------\n",
      "[[0.90810665 0.90810665 0.90810665 ... 0.57036781 0.50367042 0.39534804]\n",
      " [0.77045409 0.77045409 0.77045409 ... 0.5732391  0.50335701 0.40077842]\n",
      " [0.57436392 0.57436392 0.57436392 ... 0.5800763  0.51326306 0.39658845]\n",
      " ...\n",
      " [0.63132004 0.63132004 0.63132004 ... 0.60220402 0.5115242  0.37669904]\n",
      " [0.36971193 0.36971193 0.36971193 ... 0.56773574 0.50973704 0.40625457]\n",
      " [0.67497608 0.67497608 0.67497608 ... 0.57468218 0.50749457 0.3949462 ]]\n"
     ]
    }
   ],
   "source": [
    "#define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "#transform data\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "print(x_train)\n",
    "print('------------------------------')\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3893936, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0], x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(973485, 31)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape[0], x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "output_dim = 4\n",
    "input_dim = x_train.shape[1]\n",
    "print(input_dim)\n",
    "batch_size = 100000 \n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                2048      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 4,260\n",
      "Trainable params: 4,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3893936 samples, validate on 973485 samples\n",
      "Epoch 1/20\n",
      "3893936/3893936 [==============================] - 6s 1us/step - loss: 1.0560 - accuracy: 0.5902 - val_loss: 0.8438 - val_accuracy: 0.5852\n",
      "Epoch 2/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.7781 - accuracy: 0.7071 - val_loss: 0.6926 - val_accuracy: 0.8721\n",
      "Epoch 3/20\n",
      "3893936/3893936 [==============================] - 6s 1us/step - loss: 0.5986 - accuracy: 0.9236 - val_loss: 0.5098 - val_accuracy: 0.9235\n",
      "Epoch 4/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.4451 - accuracy: 0.9237 - val_loss: 0.3914 - val_accuracy: 0.9235\n",
      "Epoch 5/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.3554 - accuracy: 0.9237 - val_loss: 0.3297 - val_accuracy: 0.9235\n",
      "Epoch 6/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.3117 - accuracy: 0.9237 - val_loss: 0.2999 - val_accuracy: 0.9235\n",
      "Epoch 7/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.2892 - accuracy: 0.9237 - val_loss: 0.2826 - val_accuracy: 0.9235\n",
      "Epoch 8/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.2752 - accuracy: 0.9237 - val_loss: 0.2709 - val_accuracy: 0.9235\n",
      "Epoch 9/20\n",
      "3893936/3893936 [==============================] - 6s 1us/step - loss: 0.2656 - accuracy: 0.9237 - val_loss: 0.2628 - val_accuracy: 0.9235\n",
      "Epoch 10/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.2587 - accuracy: 0.9237 - val_loss: 0.2571 - val_accuracy: 0.9235\n",
      "Epoch 11/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.2538 - accuracy: 0.9237 - val_loss: 0.2527 - val_accuracy: 0.9235\n",
      "Epoch 12/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.2502 - accuracy: 0.9237 - val_loss: 0.2497 - val_accuracy: 0.9235\n",
      "Epoch 13/20\n",
      "3893936/3893936 [==============================] - 6s 1us/step - loss: 0.2477 - accuracy: 0.9237 - val_loss: 0.2476 - val_accuracy: 0.9235\n",
      "Epoch 14/20\n",
      "3893936/3893936 [==============================] - 6s 1us/step - loss: 0.2458 - accuracy: 0.9237 - val_loss: 0.2460 - val_accuracy: 0.9235\n",
      "Epoch 15/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.2443 - accuracy: 0.9237 - val_loss: 0.2445 - val_accuracy: 0.9235\n",
      "Epoch 16/20\n",
      "3893936/3893936 [==============================] - 6s 1us/step - loss: 0.2432 - accuracy: 0.9237 - val_loss: 0.2434 - val_accuracy: 0.9235\n",
      "Epoch 17/20\n",
      "3893936/3893936 [==============================] - 6s 1us/step - loss: 0.2423 - accuracy: 0.9237 - val_loss: 0.2427 - val_accuracy: 0.9235\n",
      "Epoch 18/20\n",
      "3893936/3893936 [==============================] - 6s 1us/step - loss: 0.2415 - accuracy: 0.9237 - val_loss: 0.2418 - val_accuracy: 0.9235\n",
      "Epoch 19/20\n",
      "3893936/3893936 [==============================] - 5s 1us/step - loss: 0.2409 - accuracy: 0.9237 - val_loss: 0.2415 - val_accuracy: 0.9235\n",
      "Epoch 20/20\n",
      "3893936/3893936 [==============================] - 6s 1us/step - loss: 0.2403 - accuracy: 0.9237 - val_loss: 0.2407 - val_accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(64, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
    "model_relu.add(Dense(32, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "print(model_relu.summary())\n",
    "\n",
    "model_relu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_relu.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2(MLP+Dropout+ADAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 551)               17632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 551)               2204      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 551)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 447)               246744    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 447)               1788      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 447)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 331)               148288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 331)               1324      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 331)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 236)               78352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 236)               944       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 236)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 121)               28677     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 121)               484       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 121)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 488       \n",
      "=================================================================\n",
      "Total params: 526,925\n",
      "Trainable params: 523,553\n",
      "Non-trainable params: 3,372\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_drop = Sequential()\n",
    "\n",
    "model_drop.add(Dense(551, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(447, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(331, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(236, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(121, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model_drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3893936 samples, validate on 973485 samples\n",
      "Epoch 1/20\n",
      "3893936/3893936 [==============================] - 275s 71us/step - loss: 0.5036 - accuracy: 0.8441 - val_loss: 1.9103 - val_accuracy: 0.5852\n",
      "Epoch 2/20\n",
      "3893936/3893936 [==============================] - 273s 70us/step - loss: 0.2837 - accuracy: 0.9164 - val_loss: 2.6898 - val_accuracy: 0.5852\n",
      "Epoch 3/20\n",
      "3893936/3893936 [==============================] - 271s 70us/step - loss: 0.2693 - accuracy: 0.9204 - val_loss: 3.1034 - val_accuracy: 0.5852\n",
      "Epoch 4/20\n",
      "3893936/3893936 [==============================] - 271s 70us/step - loss: 0.2614 - accuracy: 0.9222 - val_loss: 3.2574 - val_accuracy: 0.5852\n",
      "Epoch 5/20\n",
      "3893936/3893936 [==============================] - 272s 70us/step - loss: 0.2565 - accuracy: 0.9230 - val_loss: 3.2561 - val_accuracy: 0.5852\n",
      "Epoch 6/20\n",
      "3893936/3893936 [==============================] - 271s 70us/step - loss: 0.2533 - accuracy: 0.9233 - val_loss: 2.9330 - val_accuracy: 0.5852\n",
      "Epoch 7/20\n",
      "3893936/3893936 [==============================] - 271s 70us/step - loss: 0.2511 - accuracy: 0.9234 - val_loss: 2.3924 - val_accuracy: 0.5852\n",
      "Epoch 8/20\n",
      "3893936/3893936 [==============================] - 271s 70us/step - loss: 0.2493 - accuracy: 0.9235 - val_loss: 1.9191 - val_accuracy: 0.5852\n",
      "Epoch 9/20\n",
      "3893936/3893936 [==============================] - 270s 69us/step - loss: 0.2479 - accuracy: 0.9236 - val_loss: 1.0359 - val_accuracy: 0.7238\n",
      "Epoch 10/20\n",
      "3893936/3893936 [==============================] - 271s 70us/step - loss: 0.2464 - accuracy: 0.9236 - val_loss: 0.6640 - val_accuracy: 0.8114\n",
      "Epoch 11/20\n",
      "3893936/3893936 [==============================] - 271s 70us/step - loss: 0.2449 - accuracy: 0.9236 - val_loss: 0.4795 - val_accuracy: 0.8693\n",
      "Epoch 12/20\n",
      "3893936/3893936 [==============================] - 271s 70us/step - loss: 0.2427 - accuracy: 0.9237 - val_loss: 0.3495 - val_accuracy: 0.9198\n",
      "Epoch 13/20\n",
      "3893936/3893936 [==============================] - 270s 69us/step - loss: 0.2405 - accuracy: 0.9237 - val_loss: 0.3250 - val_accuracy: 0.9235\n",
      "Epoch 14/20\n",
      "3893936/3893936 [==============================] - 272s 70us/step - loss: 0.2375 - accuracy: 0.9237 - val_loss: 0.3200 - val_accuracy: 0.9235\n",
      "Epoch 15/20\n",
      "3893936/3893936 [==============================] - 274s 70us/step - loss: 0.2293 - accuracy: 0.9235 - val_loss: 0.2864 - val_accuracy: 0.9235\n",
      "Epoch 16/20\n",
      "3893936/3893936 [==============================] - 273s 70us/step - loss: 0.2140 - accuracy: 0.9231 - val_loss: 0.3222 - val_accuracy: 0.9234\n",
      "Epoch 17/20\n",
      "3893936/3893936 [==============================] - 274s 70us/step - loss: 0.2023 - accuracy: 0.9253 - val_loss: 0.3600 - val_accuracy: 0.9235\n",
      "Epoch 18/20\n",
      "3893936/3893936 [==============================] - 285s 73us/step - loss: 0.1943 - accuracy: 0.9289 - val_loss: 0.3140 - val_accuracy: 0.9235\n",
      "Epoch 19/20\n",
      "3893936/3893936 [==============================] - 281s 72us/step - loss: 0.1879 - accuracy: 0.9322 - val_loss: 0.7139 - val_accuracy: 0.7820\n",
      "Epoch 20/20\n",
      "3893936/3893936 [==============================] - 281s 72us/step - loss: 0.1842 - accuracy: 0.9340 - val_loss: 1.7042 - val_accuracy: 0.7048\n"
     ]
    }
   ],
   "source": [
    "model_drop.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_drop.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 3 (MLP+ReLu+ADAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 551)               17632     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 447)               246744    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 331)               148288    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 236)               78352     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 121)               28677     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 488       \n",
      "=================================================================\n",
      "Total params: 520,181\n",
      "Trainable params: 520,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 3893936 samples, validate on 973485 samples\n",
      "Epoch 1/20\n",
      "3893936/3893936 [==============================] - 49s 13us/step - loss: 0.4223 - accuracy: 0.8903 - val_loss: 0.2388 - val_accuracy: 0.9235\n",
      "Epoch 2/20\n",
      "3893936/3893936 [==============================] - 50s 13us/step - loss: 0.2342 - accuracy: 0.9237 - val_loss: 0.2329 - val_accuracy: 0.9235\n",
      "Epoch 3/20\n",
      "3893936/3893936 [==============================] - 50s 13us/step - loss: 0.2286 - accuracy: 0.9237 - val_loss: 0.2291 - val_accuracy: 0.9235\n",
      "Epoch 4/20\n",
      "3893936/3893936 [==============================] - 52s 13us/step - loss: 0.2275 - accuracy: 0.9238 - val_loss: 0.2272 - val_accuracy: 0.9235\n",
      "Epoch 5/20\n",
      "3893936/3893936 [==============================] - 52s 13us/step - loss: 0.2188 - accuracy: 0.9240 - val_loss: 0.2245 - val_accuracy: 0.9230\n",
      "Epoch 6/20\n",
      "3893936/3893936 [==============================] - 52s 13us/step - loss: 0.2138 - accuracy: 0.9243 - val_loss: 0.2051 - val_accuracy: 0.9239\n",
      "Epoch 7/20\n",
      "3893936/3893936 [==============================] - 52s 13us/step - loss: 0.2135 - accuracy: 0.9240 - val_loss: 0.2026 - val_accuracy: 0.9243\n",
      "Epoch 8/20\n",
      "3893936/3893936 [==============================] - 52s 13us/step - loss: 0.1954 - accuracy: 0.9264 - val_loss: 0.2201 - val_accuracy: 0.9222\n",
      "Epoch 9/20\n",
      "3893936/3893936 [==============================] - 52s 13us/step - loss: 0.1891 - accuracy: 0.9283 - val_loss: 0.1805 - val_accuracy: 0.9298\n",
      "Epoch 10/20\n",
      "3893936/3893936 [==============================] - 52s 13us/step - loss: 0.2008 - accuracy: 0.9258 - val_loss: 0.1819 - val_accuracy: 0.9271\n",
      "Epoch 11/20\n",
      "3893936/3893936 [==============================] - 52s 13us/step - loss: 0.1782 - accuracy: 0.9314 - val_loss: 0.1879 - val_accuracy: 0.9235\n",
      "Epoch 12/20\n",
      "3893936/3893936 [==============================] - 53s 14us/step - loss: 0.1794 - accuracy: 0.9303 - val_loss: 0.1742 - val_accuracy: 0.9318\n",
      "Epoch 13/20\n",
      "3893936/3893936 [==============================] - 53s 13us/step - loss: 0.1675 - accuracy: 0.9358 - val_loss: 0.1655 - val_accuracy: 0.9397\n",
      "Epoch 14/20\n",
      "3893936/3893936 [==============================] - 52s 13us/step - loss: 0.1609 - accuracy: 0.9395 - val_loss: 0.1544 - val_accuracy: 0.9449\n",
      "Epoch 15/20\n",
      "3893936/3893936 [==============================] - 53s 14us/step - loss: 0.1640 - accuracy: 0.9371 - val_loss: 0.1542 - val_accuracy: 0.9422\n",
      "Epoch 16/20\n",
      "3893936/3893936 [==============================] - 53s 14us/step - loss: 0.1522 - accuracy: 0.9427 - val_loss: 0.1570 - val_accuracy: 0.9397\n",
      "Epoch 17/20\n",
      "3893936/3893936 [==============================] - 53s 14us/step - loss: 0.1678 - accuracy: 0.9351 - val_loss: 0.1584 - val_accuracy: 0.9411\n",
      "Epoch 18/20\n",
      "3893936/3893936 [==============================] - 53s 14us/step - loss: 0.1505 - accuracy: 0.9427 - val_loss: 0.1774 - val_accuracy: 0.9298\n",
      "Epoch 19/20\n",
      "3893936/3893936 [==============================] - 53s 14us/step - loss: 0.1550 - accuracy: 0.9398 - val_loss: 0.2138 - val_accuracy: 0.9221\n",
      "Epoch 20/20\n",
      "3893936/3893936 [==============================] - 53s 14us/step - loss: 0.1516 - accuracy: 0.9427 - val_loss: 0.1505 - val_accuracy: 0.9408\n"
     ]
    }
   ],
   "source": [
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(551, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.062, seed=None)))\n",
    "model_relu.add(Dense(447, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(331, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(236, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(121, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.125, seed=None)) )\n",
    "model_relu.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "print(model_relu.summary())\n",
    "\n",
    "model_relu.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_relu.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 4 (MLP+Dropout+ADAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 438)               14016     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 438)               1752      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 438)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 276)               121164    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 276)               1104      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 276)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 157)               43489     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 157)               628       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 157)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 632       \n",
      "=================================================================\n",
      "Total params: 182,785\n",
      "Trainable params: 181,043\n",
      "Non-trainable params: 1,742\n",
      "_________________________________________________________________\n",
      "Train on 3893936 samples, validate on 973485 samples\n",
      "Epoch 1/20\n",
      "3893936/3893936 [==============================] - 140s 36us/step - loss: 0.5485 - accuracy: 0.8234 - val_loss: 1.8676 - val_accuracy: 0.5852\n",
      "Epoch 2/20\n",
      "3893936/3893936 [==============================] - 140s 36us/step - loss: 0.2902 - accuracy: 0.9155 - val_loss: 2.7481 - val_accuracy: 0.5852\n",
      "Epoch 3/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2711 - accuracy: 0.9204 - val_loss: 3.3677 - val_accuracy: 0.5852\n",
      "Epoch 4/20\n",
      "3893936/3893936 [==============================] - 142s 36us/step - loss: 0.2610 - accuracy: 0.9224 - val_loss: 3.7707 - val_accuracy: 0.5852\n",
      "Epoch 5/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2552 - accuracy: 0.9230 - val_loss: 3.9656 - val_accuracy: 0.5852\n",
      "Epoch 6/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2513 - accuracy: 0.9233 - val_loss: 3.9726 - val_accuracy: 0.5852\n",
      "Epoch 7/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2486 - accuracy: 0.9234 - val_loss: 3.7957 - val_accuracy: 0.5852\n",
      "Epoch 8/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2465 - accuracy: 0.9235 - val_loss: 3.3945 - val_accuracy: 0.5852\n",
      "Epoch 9/20\n",
      "3893936/3893936 [==============================] - 140s 36us/step - loss: 0.2443 - accuracy: 0.9236 - val_loss: 2.8866 - val_accuracy: 0.5852\n",
      "Epoch 10/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2428 - accuracy: 0.9236 - val_loss: 2.4276 - val_accuracy: 0.5852\n",
      "Epoch 11/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2416 - accuracy: 0.9236 - val_loss: 1.3003 - val_accuracy: 0.6919\n",
      "Epoch 12/20\n",
      "3893936/3893936 [==============================] - 140s 36us/step - loss: 0.2406 - accuracy: 0.9236 - val_loss: 0.8950 - val_accuracy: 0.7566\n",
      "Epoch 13/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2395 - accuracy: 0.9236 - val_loss: 0.4709 - val_accuracy: 0.8558\n",
      "Epoch 14/20\n",
      "3893936/3893936 [==============================] - 140s 36us/step - loss: 0.2387 - accuracy: 0.9236 - val_loss: 0.3367 - val_accuracy: 0.9027\n",
      "Epoch 15/20\n",
      "3893936/3893936 [==============================] - 140s 36us/step - loss: 0.2378 - accuracy: 0.9237 - val_loss: 0.3123 - val_accuracy: 0.9019\n",
      "Epoch 16/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2366 - accuracy: 0.9236 - val_loss: 0.2562 - val_accuracy: 0.9207\n",
      "Epoch 17/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2355 - accuracy: 0.9237 - val_loss: 0.2417 - val_accuracy: 0.9240\n",
      "Epoch 18/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2340 - accuracy: 0.9237 - val_loss: 0.2408 - val_accuracy: 0.9239\n",
      "Epoch 19/20\n",
      "3893936/3893936 [==============================] - 139s 36us/step - loss: 0.2320 - accuracy: 0.9237 - val_loss: 0.2360 - val_accuracy: 0.9236\n",
      "Epoch 20/20\n",
      "3893936/3893936 [==============================] - 141s 36us/step - loss: 0.2294 - accuracy: 0.9239 - val_loss: 0.2389 - val_accuracy: 0.9235\n"
     ]
    }
   ],
   "source": [
    "model_drop = Sequential()\n",
    "\n",
    "model_drop.add(Dense(438, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(276, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(157, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model_drop.summary()\n",
    "\n",
    "model_drop.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_drop.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 612)               19584     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 612)               2448      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 612)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 324)               198612    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 324)               1296      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 324)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4)                 1300      \n",
      "=================================================================\n",
      "Total params: 223,240\n",
      "Trainable params: 221,368\n",
      "Non-trainable params: 1,872\n",
      "_________________________________________________________________\n",
      "Train on 3893936 samples, validate on 973485 samples\n",
      "Epoch 1/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.6970 - accuracy: 0.7719 - val_loss: 1.2457 - val_accuracy: 0.5852\n",
      "Epoch 2/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.3250 - accuracy: 0.9091 - val_loss: 1.7034 - val_accuracy: 0.5852\n",
      "Epoch 3/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2890 - accuracy: 0.9165 - val_loss: 1.9114 - val_accuracy: 0.5852\n",
      "Epoch 4/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2712 - accuracy: 0.9209 - val_loss: 2.0379 - val_accuracy: 0.5852\n",
      "Epoch 5/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2604 - accuracy: 0.9226 - val_loss: 2.1646 - val_accuracy: 0.5852\n",
      "Epoch 6/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2533 - accuracy: 0.9231 - val_loss: 2.2571 - val_accuracy: 0.5852\n",
      "Epoch 7/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2487 - accuracy: 0.9233 - val_loss: 2.2516 - val_accuracy: 0.5852\n",
      "Epoch 8/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2450 - accuracy: 0.9233 - val_loss: 2.2038 - val_accuracy: 0.5852\n",
      "Epoch 9/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2424 - accuracy: 0.9234 - val_loss: 2.0219 - val_accuracy: 0.5852\n",
      "Epoch 10/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2399 - accuracy: 0.9234 - val_loss: 1.6243 - val_accuracy: 0.5852\n",
      "Epoch 11/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2379 - accuracy: 0.9235 - val_loss: 1.2543 - val_accuracy: 0.5975\n",
      "Epoch 12/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2359 - accuracy: 0.9235 - val_loss: 0.8493 - val_accuracy: 0.7141\n",
      "Epoch 13/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2340 - accuracy: 0.9236 - val_loss: 0.4789 - val_accuracy: 0.8535\n",
      "Epoch 14/20\n",
      "3893936/3893936 [==============================] - 155s 40us/step - loss: 0.2322 - accuracy: 0.9237 - val_loss: 0.3535 - val_accuracy: 0.9051\n",
      "Epoch 15/20\n",
      "3893936/3893936 [==============================] - 153s 39us/step - loss: 0.2303 - accuracy: 0.9238 - val_loss: 0.3146 - val_accuracy: 0.9139\n",
      "Epoch 16/20\n",
      "3893936/3893936 [==============================] - 154s 39us/step - loss: 0.2282 - accuracy: 0.9240 - val_loss: 0.2968 - val_accuracy: 0.9148\n",
      "Epoch 17/20\n",
      "3893936/3893936 [==============================] - 153s 39us/step - loss: 0.2254 - accuracy: 0.9244 - val_loss: 0.2746 - val_accuracy: 0.9222\n",
      "Epoch 18/20\n",
      "3893936/3893936 [==============================] - 154s 39us/step - loss: 0.2231 - accuracy: 0.9248 - val_loss: 0.2559 - val_accuracy: 0.9241\n",
      "Epoch 19/20\n",
      "3893936/3893936 [==============================] - 154s 39us/step - loss: 0.2210 - accuracy: 0.9253 - val_loss: 0.2595 - val_accuracy: 0.9239\n",
      "Epoch 20/20\n",
      "3893936/3893936 [==============================] - 153s 39us/step - loss: 0.2189 - accuracy: 0.9259 - val_loss: 0.2444 - val_accuracy: 0.9236\n"
     ]
    }
   ],
   "source": [
    "model_drop = Sequential()\n",
    "\n",
    "model_drop.add(Dense(612, activation='relu', input_shape=(input_dim,), kernel_initializer=RandomNormal(mean=0.0, stddev=0.039, seed=None)))\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(324, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.55, seed=None)) )\n",
    "model_drop.add(BatchNormalization())\n",
    "model_drop.add(Dropout(0.5))\n",
    "\n",
    "model_drop.add(Dense(output_dim, activation='softmax'))\n",
    "\n",
    "\n",
    "model_drop.summary()\n",
    "\n",
    "model_drop.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model_drop.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "\n",
    "# MODEL 3 GAVE THE BEST RESULT - \n",
    "# val_loss: 0.1505 \n",
    "# val_accuracy: 0.9408"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------------------------------+----------+\n",
      "| S.NO |                    MODEL                    | LOG LOSS |\n",
      "+------+---------------------------------------------+----------+\n",
      "|  1   |           MODEL 1: 3 Dense Layers           |  0.2407  |\n",
      "|  2   | MODEL 2: 6 Dense Layers with BN and Dropout |  1.7042  |\n",
      "|  3   |           MODEL 3: 6 Dense Layers           |  0.1505  |\n",
      "|  4   | MODEL 4: 4 Dense Layers with BN and Dropout |  0.2389  |\n",
      "|  5   | MODEL 5: 3 Dense Layers with BN and Dropout |  0.2444  |\n",
      "+------+---------------------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "    \n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"S.NO\",\"MODEL\",\"LOG LOSS\"]\n",
    "\n",
    "x.add_row([\"1\",\"MODEL 1: 3 Dense Layers\",0.2407])\n",
    "x.add_row([\"2\",\"MODEL 2: 6 Dense Layers with BN and Dropout\",1.7042])\n",
    "x.add_row([\"3\",\"MODEL 3: 6 Dense Layers\",0.1505])\n",
    "x.add_row([\"4\",\"MODEL 4: 4 Dense Layers with BN and Dropout\",0.2389])\n",
    "x.add_row([\"5\",\"MODEL 5: 3 Dense Layers with BN and Dropout\",0.2444])\n",
    "\n",
    "# Printing the Table\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
